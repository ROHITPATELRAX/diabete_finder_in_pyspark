{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0b58135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "28b35856",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Demo for better understanding').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "09abec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('titanic_test.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8fdd972e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "834e7f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+--------------------+------+------+-----+-----+----------------+--------+-----+--------+----+-----+--------------------+\n",
      "|passenger_id|pclass|                name|   sex|   age|sibsp|parch|          ticket|    fare|cabin|embarked|boat| body|           home.dest|\n",
      "+------------+------+--------------------+------+------+-----+-----+----------------+--------+-----+--------+----+-----+--------------------+\n",
      "|         295|     1|Thayer, Mr. John ...|  male|  17.0|    0|    2|           17421|110.8833|  C70|       C|   B| null|       Haverford, PA|\n",
      "|        1150|     3|Risien, Mr. Samue...|  male|  null|    0|    0|          364498|    14.5| null|       S|null| null|                null|\n",
      "|          89|     1|Davidson, Mr. Tho...|  male|  31.0|    1|    0|      F.C. 12750|    52.0|  B71|       S|null| null|        Montreal, PQ|\n",
      "|        1063|     3|Nirva, Mr. Iisakk...|  male|  41.0|    0|    0|SOTON/O2 3101272|   7.125| null|       S|null| null| Finland Sudbury, ON|\n",
      "|        1020|     3|  Minkoff, Mr. Lazar|  male|  21.0|    0|    0|          349211|  7.8958| null|       S|null| null|                null|\n",
      "|         747|     3|Danbom, Master. G...|  male|0.3333|    0|    2|          347080|    14.4| null|       S|null| null|         Stanton, IA|\n",
      "|         368|     2|Chapman, Mr. John...|  male|  37.0|    1|    0|     SC/AH 29037|    26.0| null|       S|null| 17.0|Cornwall / Spokan...|\n",
      "|        1047|     3|\"Najib, Miss. Ade...|female|  15.0|    0|    0|            2667|   7.225| null|       C|   C| null|                null|\n",
      "|         569|     2|Sweet, Mr. George...|  male|  14.0|    0|    0|          220845|    65.0| null|       S|null| null|Somerset / Bernar...|\n",
      "|         232|     1|Porter, Mr. Walte...|  male|  47.0|    0|    0|          110465|    52.0| C110|       S|null|207.0|       Worcester, MA|\n",
      "|         365|     2|Carter, Mrs. Erne...|female|  44.0|    1|    0|          244252|    26.0| null|       S|null| null|              London|\n",
      "|         351|     2|Brown, Mr. Thomas...|  male|  60.0|    1|    1|           29750|    39.0| null|       S|null| null|Cape Town, South ...|\n",
      "|         535|     2|Phillips, Mr. Esc...|  male|  43.0|    0|    1|     S.O./P.P. 2|    21.0| null|       S|null| null|   Ilfracombe, Devon|\n",
      "|         287|     1|Sutton, Mr. Frede...|  male|  61.0|    0|    0|           36963| 32.3208|  D50|       S|null| 46.0|     Haddenfield, NJ|\n",
      "|         767|     3|Demetri, Mr. Marinko|  male|  null|    0|    0|          349238|  7.8958| null|       S|null| null|                null|\n",
      "|         528|     2|\"Parkes, Mr. Fran...|  male|  null|    0|    0|          239853|     0.0| null|       S|null| null|             Belfast|\n",
      "|         430|     2|\"Harper, Miss. An...|female|   6.0|    0|    1|          248727|    33.0| null|       S|  11| null|Denmark Hill, Sur...|\n",
      "|          60|     1|Cavendish, Mr. Ty...|  male|  36.0|    1|    0|           19877|   78.85|  C46|       S|null|172.0|Little Onn Hall, ...|\n",
      "|        1212|     3|Slabenoff, Mr. Petco|  male|  null|    0|    0|          349214|  7.8958| null|       S|null| null|                null|\n",
      "|         462|     2|Jefferys, Mr. Cli...|  male|  24.0|    2|    0|      C.A. 31029|    31.5| null|       S|null| null|Guernsey / Elizab...|\n",
      "+------------+------+--------------------+------+------+-----+-----+----------------+--------+-----+--------+----+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "116a5ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredDF=df.drop('home.dest','ticket','body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c8216fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'passenger_id'>\n",
      "Column<'pclass'>\n",
      "Column<'name'>\n",
      "Column<'sex'>\n",
      "Column<'age'>\n",
      "Column<'sibsp'>\n",
      "Column<'parch'>\n",
      "Column<'fare'>\n",
      "Column<'cabin'>\n",
      "Column<'embarked'>\n",
      "Column<'boat'>\n"
     ]
    }
   ],
   "source": [
    "for c in filteredDF.columns:\n",
    "    print(col(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "db3eab3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_id: string (nullable = true)\n",
      " |-- pclass: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- sibsp: string (nullable = true)\n",
      " |-- parch: string (nullable = true)\n",
      " |-- fare: string (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      " |-- boat: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filteredDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ea7f9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "typecastedDF=filteredDF.select(\n",
    "    *(\n",
    "        col(c).cast('float') if ('p' in c) else col(c) for c in filteredDF.columns \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5149c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count,when,isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cb08899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+-------------------------------------------------+---------------------------------------------+-------------------------------------------+-------------------------------------------+-----------------------------------------------+-----------------------------------------------+---------------------------------------------+-----------------------------------------------+-----------------------------------------------------+---------------------------------------------+\n",
      "|count(CASE WHEN (passenger_id IS NULL) THEN passenger_id END)|count(CASE WHEN (pclass IS NULL) THEN pclass END)|count(CASE WHEN (name IS NULL) THEN name END)|count(CASE WHEN (sex IS NULL) THEN sex END)|count(CASE WHEN (age IS NULL) THEN age END)|count(CASE WHEN (sibsp IS NULL) THEN sibsp END)|count(CASE WHEN (parch IS NULL) THEN parch END)|count(CASE WHEN (fare IS NULL) THEN fare END)|count(CASE WHEN (cabin IS NULL) THEN cabin END)|count(CASE WHEN (embarked IS NULL) THEN embarked END)|count(CASE WHEN (boat IS NULL) THEN boat END)|\n",
      "+-------------------------------------------------------------+-------------------------------------------------+---------------------------------------------+-------------------------------------------+-------------------------------------------+-----------------------------------------------+-----------------------------------------------+---------------------------------------------+-----------------------------------------------+-----------------------------------------------------+---------------------------------------------+\n",
      "|                                                            0|                                                0|                                            0|                                          0|                                         89|                                              0|                                              0|                                            0|                                            355|                                                    1|                                          281|\n",
      "+-------------------------------------------------------------+-------------------------------------------------+---------------------------------------------+-------------------------------------------+-------------------------------------------+-----------------------------------------------+-----------------------------------------------+---------------------------------------------+-----------------------------------------------+-----------------------------------------------------+---------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "typecastedDF.select(\n",
    "    [\n",
    "        count(when(col(c).isNull(),c)) for c in typecastedDF.columns\n",
    "    ]\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5fe92377",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Column age must be of type numeric but was actually of type string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature\u001b[39;00m \u001b[39mimport\u001b[39;00m Imputer\n\u001b[1;32m      3\u001b[0m imputer \u001b[39m=\u001b[39m Imputer(\n\u001b[1;32m      4\u001b[0m     inputCols\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mage\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m     outputCols\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mage\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m model\u001b[39m=\u001b[39mimputer\u001b[39m.\u001b[39;49mfit(typecastedDF)\n\u001b[1;32m      9\u001b[0m imputed_data\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mtransform(typecastedDF)\n\u001b[1;32m     11\u001b[0m imputed_data\u001b[39m.\u001b[39mfillna(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/Set-Ups/spark-3.3.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(params)\u001b[39m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(dataset)\n\u001b[1;32m    206\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m~/Downloads/Set-Ups/spark-3.3.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/ml/wrapper.py:383\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit\u001b[39m(\u001b[39mself\u001b[39m, dataset: DataFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m JM:\n\u001b[0;32m--> 383\u001b[0m     java_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_java(dataset)\n\u001b[1;32m    384\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    385\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_copyValues(model)\n",
      "File \u001b[0;32m~/Downloads/Set-Ups/spark-3.3.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/ml/wrapper.py:380\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_java_obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 380\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_java_obj\u001b[39m.\u001b[39;49mfit(dataset\u001b[39m.\u001b[39;49m_jdf)\n",
      "File \u001b[0;32m~/Downloads/Set-Ups/spark-3.3.1-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/Downloads/Set-Ups/spark-3.3.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Column age must be of type numeric but was actually of type string."
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['age'],\n",
    "    outputCols=['age']\n",
    ")\n",
    "model=imputer.fit(typecastedDF)\n",
    "\n",
    "imputed_data=model.transform(typecastedDF)\n",
    "\n",
    "imputed_data.fillna('')\n",
    "\n",
    "imputed_data.select(\n",
    "    [\n",
    "        count(when(col(c).isNull(),c)) for c in imputed_data.columns\n",
    "    ]\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9cc4a5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+-----+--------+----+\n",
      "|pclass|      age|sibsp|parch|    fare|boat|\n",
      "+------+---------+-----+-----+--------+----+\n",
      "|   1.0|     17.0|  0.0|  2.0|110.8833|   B|\n",
      "|   3.0|30.541216|  0.0|  0.0|    14.5|null|\n",
      "|   1.0|     31.0|  1.0|  0.0|    52.0|null|\n",
      "|   3.0|     41.0|  0.0|  0.0|   7.125|null|\n",
      "|   3.0|     21.0|  0.0|  0.0|  7.8958|null|\n",
      "|   3.0|   0.3333|  0.0|  2.0|    14.4|null|\n",
      "|   2.0|     37.0|  1.0|  0.0|    26.0|null|\n",
      "|   3.0|     15.0|  0.0|  0.0|   7.225|   C|\n",
      "|   2.0|     14.0|  0.0|  0.0|    65.0|null|\n",
      "|   1.0|     47.0|  0.0|  0.0|    52.0|null|\n",
      "|   2.0|     44.0|  1.0|  0.0|    26.0|null|\n",
      "|   2.0|     60.0|  1.0|  1.0|    39.0|null|\n",
      "|   2.0|     43.0|  0.0|  1.0|    21.0|null|\n",
      "|   1.0|     61.0|  0.0|  0.0| 32.3208|null|\n",
      "|   3.0|30.541216|  0.0|  0.0|  7.8958|null|\n",
      "|   2.0|30.541216|  0.0|  0.0|     0.0|null|\n",
      "|   2.0|      6.0|  0.0|  1.0|    33.0|  11|\n",
      "|   1.0|     36.0|  1.0|  0.0|   78.85|null|\n",
      "|   3.0|30.541216|  0.0|  0.0|  7.8958|null|\n",
      "|   2.0|     24.0|  2.0|  0.0|    31.5|null|\n",
      "+------+---------+-----+-----+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filteredDF=imputed_data.drop('passenger_id','Cabin','Embarked','Name','sex')\n",
    "filteredDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5aa47156",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'splearn.preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msplearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m      2\u001b[0m le\u001b[39m=\u001b[39mLabelEncoder()\n\u001b[1;32m      3\u001b[0m le\u001b[39m.\u001b[39mfit_transform(filteredDF[\u001b[39m'\u001b[39m\u001b[39msex\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshow())\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'splearn.preprocessing'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a54951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7870c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
